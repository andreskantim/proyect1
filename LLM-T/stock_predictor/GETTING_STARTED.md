# Getting Started - MarketGPT

Gu√≠a completa para instalar, configurar y comenzar a usar MarketGPT.

---

## üìã Tabla de Contenidos

1. [Instalaci√≥n](#instalaci√≥n)
2. [Verificaci√≥n](#verificaci√≥n)
3. [Uso con Claude](#uso-con-claude)
4. [Primer Entrenamiento](#primer-entrenamiento)
5. [Monitoreo](#monitoreo)
6. [Troubleshooting](#troubleshooting)

---

## üöÄ Instalaci√≥n

### 1. Activar Environment Conda

El proyecto usa el environment `llm-training` instalado en CESGA:

```bash
# Activar el entorno
conda activate llm-training

# Verificar activaci√≥n
which python
# Deber√≠a mostrar: /mnt/netapp2/Store_uni/.../llm-training/bin/python
```

### 2. Navegar al Proyecto

```bash
# Ir al directorio del proyecto
cd /mnt/netapp2/Home_FT2/home/ulc/cursos/curso396/LLM-T/stock_predictor
```

### 3. Instalar Dependencias

```bash
# Asegurarse de que PyTorch est√© instalado con CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Instalar otras dependencias
pip install -r requirements_gpu.txt
```

**Paquetes principales instalados:**
- Python 3.10+
- PyTorch 2.7+ con CUDA 11.8
- pandas, scikit-learn
- yfinance (para descargar datos de mercado)
- tqdm (barras de progreso)
- requests (para APIs)

---

## ‚úÖ Verificaci√≥n

### Script de Verificaci√≥n Autom√°tica

```bash
# Ejecutar script de verificaci√≥n
python verify_installation.py
```

**Salida esperada:**
```
‚úì Python version OK: 3.10.x
‚úì PyTorch installed: 2.7.x
‚úì CUDA available: True
‚úì GPU count: 1-2
‚úì Required packages: OK
‚úì All tests passed!
```

### Verificaci√≥n Manual

```bash
# Verificar Python
python --version

# Verificar PyTorch y CUDA
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA:', torch.cuda.is_available())"

# Verificar GPUs disponibles
python -c "import torch; print('GPUs:', torch.cuda.device_count())"
```

---

## ü§ñ Uso con Claude

MarketGPT est√° dise√±ado para trabajar con Claude Code. Esta secci√≥n explica c√≥mo maximizar la colaboraci√≥n.

### Comando `/context` (Recomendado)

**Al iniciar cada sesi√≥n con Claude**, ejecuta:

```
/context
```

O usa el atajo:

```
/ctx
```

**¬øQu√© hace?**
- Carga autom√°ticamente `CLAUDE_CONTEXT.md`
- Proporciona a Claude contexto completo del proyecto
- Incluye arquitectura, estado actual, y pendientes
- Facilita que Claude entienda el proyecto sin repetir informaci√≥n

### Estructura de Documentaci√≥n para Claude

```
stock_predictor/
‚îú‚îÄ‚îÄ README.md              ‚Üê Documento principal (overview)
‚îú‚îÄ‚îÄ GETTING_STARTED.md     ‚Üê Est√°s aqu√≠ (instalaci√≥n y setup)
‚îú‚îÄ‚îÄ ARCHITECTURE.md        ‚Üê Detalles t√©cnicos profundos
‚îú‚îÄ‚îÄ TRAINING.md            ‚Üê Gu√≠a de entrenamiento multi-GPU
‚îú‚îÄ‚îÄ REFERENCE.md           ‚Üê Referencia r√°pida de conceptos
‚îú‚îÄ‚îÄ PROJECT_STATUS.md      ‚Üê Estado actual del proyecto
‚îî‚îÄ‚îÄ CLAUDE_CONTEXT.md      ‚Üê Contexto para Claude (usado por /context)
```

### Cu√°ndo Usar Cada Documento

| Pregunta | Documento a Consultar |
|----------|----------------------|
| "¬øC√≥mo instalo el proyecto?" | `GETTING_STARTED.md` (este) |
| "¬øC√≥mo funciona la arquitectura?" | `ARCHITECTURE.md` |
| "¬øC√≥mo entreno un modelo?" | `TRAINING.md` |
| "¬øQu√© significa walk-forward?" | `REFERENCE.md` |
| "¬øQu√© est√° implementado?" | `PROJECT_STATUS.md` |
| "Contexto para nueva sesi√≥n" | `/context` (carga `CLAUDE_CONTEXT.md`) |

### Workflow Recomendado con Claude

#### Primera Vez en el Proyecto

1. **Lee este archivo** (GETTING_STARTED.md) ‚úì
2. **Ejecuta `/context`** para cargar contexto en Claude
3. **Pregunta a Claude**: "¬øCu√°l es el overview del proyecto?"
4. **Lee REFERENCE.md** para familiarizarte con conceptos clave
5. **Explora la estructura** de carpetas y archivos

#### Cada Nueva Sesi√≥n

1. **Ejecuta `/context`** inmediatamente
2. **Pregunta a Claude**: "¬øEn qu√© est√°bamos trabajando?"
3. **Consulta PROJECT_STATUS.md** para ver estado actual
4. **Contin√∫a** desde donde lo dejaste

#### Antes de Implementar Algo Nuevo

1. **Consulta ARCHITECTURE.md** para entender la arquitectura
2. **Revisa c√≥digo existente** en `common/` para ver patrones
3. **Planifica con Claude** usando el contexto cargado
4. **Implementa** siguiendo los est√°ndares del proyecto

### Consejos para Aprovechar `/context`

‚úÖ **Ejec√∫talo siempre al inicio**: Aunque Claude "deba recordar", es mejor cargarlo
‚úÖ **√ösalo despu√©s de pausas largas**: Si llevas horas sin trabajar, rec√°rgalo
‚úÖ **Actualiza CLAUDE_CONTEXT.md**: Cuando completes algo importante, actualiza el archivo
‚úÖ **Mant√©n sincronizado**: Si cambias arquitectura, actualiza primero CLAUDE_CONTEXT.md

### Comunicaci√≥n Efectiva con Claude

Cuando Claude tiene el contexto cargado, puedes hacer preguntas como:

- "¬øQu√© falta por implementar?"
- "¬øC√≥mo funciona el walk-forward analysis?"
- "¬øD√≥nde est√°n los scripts de entrenamiento?"
- "¬øCu√°l es el pr√≥ximo paso en el roadmap?"

Claude responder√° bas√°ndose en el contexto del proyecto.

---

## üéØ Primer Entrenamiento

### Opci√≥n A: Test R√°pido Local (Opcional)

Antes del entrenamiento completo, puedes hacer un test r√°pido:

```bash
# Test r√°pido con datos peque√±os (30 min aprox)
python train_bitcoin.py \
    --config configs/quick_test.json \
    --output_dir checkpoints/quick_test \
    --log_dir logs/quick_test \
    --device cuda
```

Esto verifica que todo funciona antes de lanzar trabajos largos en SLURM.

### Opci√≥n B: Entrenamiento Completo en A100

#### Paso 1: Editar Scripts SLURM (Primera Vez)

```bash
# Editar para recibir notificaciones por email
nano case_c_crypto/slurm_scripts/train_crypto_a100.sh

# Cambiar esta l√≠nea:
#SBATCH --mail-user=your_email@domain.com
# Por tu email real
```

#### Paso 2: Lanzar Case C (Recomendado para empezar)

Case C es el m√°s r√°pido (1-2 d√≠as) y perfecto para validar el sistema:

```bash
# M√©todo 1: Script interactivo (recomendado)
cd case_c_crypto
bash launch.sh
# Selecciona opci√≥n 1: Submit SLURM job

# M√©todo 2: Directo
cd case_c_crypto/slurm_scripts
sbatch train_crypto_a100.sh
```

**Guardar Job ID:**
```bash
# El comando sbatch devuelve algo como:
# Submitted batch job 2311562
JOB_ID=2311562
```

#### Paso 3: Otros Cases (Opcional)

Una vez validado Case C, puedes entrenar los dem√°s:

**Case B** (100 assets, 3-5 d√≠as):
```bash
cd case_b_reduced/slurm_scripts
sbatch train_reduced_a100.sh
```

**Case A** (600 assets, 7-10 d√≠as):
```bash
cd case_a_full_market/slurm_scripts
sbatch train_full_a100.sh
```

---

## üìä Monitoreo

### Verificar Estado del Job

```bash
# Ver tus jobs activos
squeue -u $(whoami)

# Ver estado espec√≠fico
squeue -j $JOB_ID

# Ver detalles completos
scontrol show job $JOB_ID
```

### Ver Logs en Tiempo Real

```bash
# Ver output
tail -f case_c_crypto/logs/crypto_${JOB_ID}.out

# Ver errores
tail -f case_c_crypto/logs/crypto_${JOB_ID}.err
```

### Monitorear GPUs

```bash
# Identificar en qu√© nodo est√° corriendo
squeue -j $JOB_ID -o "%N"

# SSH al nodo (ejemplo: a100-01)
ssh a100-01

# Ver uso de GPU
nvidia-smi

# Monitoreo continuo
nvidia-smi -l 1  # actualiza cada segundo
```

**Uso esperado:**
- GPU Utilization: ~95%
- Memory Usage: 10-15GB (de 40GB)
- Temperature: <80¬∞C

### Cancelar Job (si es necesario)

```bash
# Cancelar job espec√≠fico
scancel $JOB_ID

# Cancelar todos tus jobs
scancel -u $(whoami)
```

---

## üìÇ Resultados

Los resultados se guardar√°n en:

```
case_c_crypto/checkpoints/crypto_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ best_model.pt              # Mejor modelo (por val_loss)
‚îú‚îÄ‚îÄ checkpoint_epoch_N.pt      # Checkpoints peri√≥dicos
‚îú‚îÄ‚îÄ config.json                # Configuraci√≥n usada
‚îú‚îÄ‚îÄ tokenizer.pkl              # Tokenizador entrenado
‚îú‚îÄ‚îÄ asset_info.json            # Informaci√≥n de assets
‚îú‚îÄ‚îÄ training_log.json          # Log completo de entrenamiento
‚îú‚îÄ‚îÄ data_info.json             # Estad√≠sticas de datos
‚îî‚îÄ‚îÄ test_results.json          # Resultados en test set
```

### Ver Resultados

```bash
# Ver m√©tricas finales
cat case_c_crypto/checkpoints/*/test_results.json | jq '.'

# Ver progreso de entrenamiento
cat case_c_crypto/checkpoints/*/training_log.json | jq '.epochs[-5:]'

# Listar checkpoints
ls -lh case_c_crypto/checkpoints/*/checkpoint_*.pt
```

---

## üîß Troubleshooting

### Error: Environment no activado

```bash
# Activar environment
conda activate llm-training

# Si no funciona, inicializar conda
source $STORE/miniconda3/etc/profile.d/conda.sh
conda activate llm-training
```

### Error: "CUDA out of memory"

```bash
# Editar config y reducir batch_size
nano case_c_crypto/configs/crypto_prototype.json
# Cambiar batch_size: 32 ‚Üí 16
```

### Error: Job no arranca

```bash
# Ver cola de la partici√≥n
squeue -p medium

# Ver GPUs disponibles
sinfo -p medium -o "%P %D %N %G %C %m"

# Si hay mucha cola, esperar o usar partici√≥n short para tests
```

### Error: Datos no descargan

```bash
# Test manual de descarga
python case_c_crypto/crypto_data_loader.py

# Si falla, verificar conexi√≥n internet
ping google.com
```

### Error: Import errors

```bash
# Verificar que est√°s en el directorio correcto
pwd
# Deber√≠a mostrar: .../LLM-T/stock_predictor

# Reinstalar dependencias
pip install -r requirements_gpu.txt
```

---

## üìö Comandos √ötiles SLURM

### Informaci√≥n de Jobs

```bash
# Ver todos tus jobs
squeue -u $(whoami)

# Ver detalles de un job
scontrol show job <job_id>

# Ver historial de jobs
sacct -u $(whoami)

# Ver jobs recientes con estado
sacct -u $(whoami) --format=JobID,JobName,State,Elapsed,TimeLimit
```

### Informaci√≥n del Cluster

```bash
# Ver particiones disponibles
sinfo

# Ver GPUs disponibles
sinfo -N -o "%N %G %t" | grep a100

# Ver nodos de una partici√≥n
sinfo -p medium -N
```

### Gesti√≥n de Jobs

```bash
# Cancelar job
scancel <job_id>

# Cancelar todos tus jobs
scancel -u $(whoami)

# Hold (pausar) un job pendiente
scontrol hold <job_id>

# Release (reanudar) un job en hold
scontrol release <job_id>
```

---

## ‚è±Ô∏è Tiempos Esperados

| Case | Assets | GPUs | Tiempo Estimado |
|------|--------|------|----------------|
| **C** | 20 cryptos | 2√óA100 | 1-2 d√≠as |
| **B** | 100 multi-market | 2√óA100 | 3-5 d√≠as |
| **A** | 600 todos mercados | 2√óA100 | 7-10 d√≠as |

**Nota:** Los tiempos son estimaciones. Pueden variar seg√∫n:
- Carga del cluster
- Configuraci√≥n de hiperpar√°metros
- Convergencia del modelo

---

## üéì Pr√≥ximos Pasos

### 1. Durante el Entrenamiento
- Monitorea m√©tricas en logs
- Verifica que val_loss disminuya
- Observa convergencia

### 2. Despu√©s del Entrenamiento
- Analiza resultados en test set
- Revisa training_log.json
- Compara diferentes cases (si entrenaste varios)

### 3. Fase 2: Fine-Tuning (Pr√≥ximamente)
- Scripts de fine-tuning por mercado
- Walk-forward analysis
- Especializaci√≥n de modelos

### 4. Fase 3: Se√±ales (Futuro)
- Generaci√≥n de se√±ales de trading
- Backtesting
- Validaci√≥n con benchmarks

---

## üìñ M√°s Informaci√≥n

- **Arquitectura completa**: Ver [ARCHITECTURE.md](ARCHITECTURE.md)
- **Gu√≠a de entrenamiento**: Ver [TRAINING.md](TRAINING.md)
- **Referencia r√°pida**: Ver [REFERENCE.md](REFERENCE.md)
- **Estado del proyecto**: Ver [PROJECT_STATUS.md](PROJECT_STATUS.md)

---

## üí° Consejos Finales

‚úÖ **Comienza con Case C**: Es r√°pido y valida que todo funciona
‚úÖ **Monitorea activamente**: Revisa logs regularmente
‚úÖ **Usa /context con Claude**: Facilita colaboraci√≥n
‚úÖ **Guarda Job IDs**: Anota los IDs para monitoreo
‚úÖ **S√© paciente**: El entrenamiento puede tardar d√≠as

---

**¬°Listo para empezar!** üöÄ

Si tienes dudas, consulta la documentaci√≥n o usa `/context` con Claude para obtener ayuda contextualizada.

---

**√öltima actualizaci√≥n**: 2025-01-06
