# CONTEXTO DEL PROYECTO: MarketGPT Trading System

> **Prop√≥sito**: Este archivo proporciona contexto completo del proyecto para sesiones de Claude.
> **Uso**: Ejecutar `/context` al iniciar una nueva sesi√≥n.

---

## üìã RESUMEN EJECUTIVO

**Nombre**: MarketGPT - Sistema de Trading con IA
**Objetivo**: Sistema completo de predicci√≥n de mercados financieros y generaci√≥n de se√±ales de trading (LONG/SHORT) de alta confianza
**Tecnolog√≠a**: Transformers (r√©plicas de LLM tipo GPT) entrenados con datos de bolsa + PyTorch + Multi-GPU (2√óA100)
**Ubicaci√≥n**: `/mnt/netapp2/Home_FT2/home/ulc/cursos/curso396/LLM-T/stock_predictor/`

**Concepto Clave**: Entrenamos 3 modelos base (r√©plicas de arquitectura LLM) con datos hist√≥ricos de mercados. Cada modelo aprende patrones de precios OHLC tokenizados. Luego especializamos por mercado y generamos se√±ales de trading validadas con benchmarks.

---

## üèóÔ∏è ARQUITECTURA DEL SISTEMA (3 FASES)

### FASE 1: Pre-entrenamiento General ‚úÖ IMPLEMENTADO

**Objetivo**: Entrenar 3 modelos base (r√©plicas de LLM) con datos de bolsa

**Concepto**: Entrenamos transformers estilo GPT con datos OHLC tokenizados de diferentes conjuntos de tickers. Cada modelo es una r√©plica de arquitectura LLM adaptada para series temporales financieras.

**Cases (3 Modelos Base)**:
- **Case A**: 600 tickers (US + EU + EM + Commodities + Crypto) - 7-10 d√≠as
  - Modelo universal con m√°xima cobertura
- **Case B**: 100 tickers (curated multi-market) - 3-5 d√≠as
  - Modelo baseline con activos de alta calidad
- **Case C**: 20 tickers crypto (prototipo r√°pido) - 1-2 d√≠as
  - Modelo especializado en criptomonedas

**Datos por Case**:
- Split temporal: Train 70% / Val 15% / Test 15%
- Periodo: 2014-2025 (11 a√±os de historia)
- NO divisi√≥n aleatoria (preserva causalidad temporal)
- Tickers espec√≠ficos por case (definidos en cada data loader)

**Proceso de Entrenamiento**:
1. **Train set** (70%) ‚Üí Entrena el modelo (actualiza pesos)
2. **Val set** (15%) ‚Üí Early stopping + Model selection
3. **Test set** (15%) ‚Üí Evaluaci√≥n final √öNICA (NO usado durante entrenamiento)

**Hardware por Case**: 2√óA100 GPUs, 64 CPUs, 128GB RAM

**Output**: `best_model.pt` (modelo general pre-entrenado para cada case)

---

### FASE 2: Fine-Tuning por Mercado ‚ùå PENDIENTE

**Objetivo**: Dentro de cada case (A, B, C), generar modelos especializados por tipo de mercado

**Proceso**: Partir del modelo general pre-entrenado de cada case y especializarlo para mercados espec√≠ficos usando tickers propios de cada mercado.

**Mercados Target (dentro de cada Case)**:
1. **US Stocks**: Tickers espec√≠ficos de acciones estadounidenses
2. **EU Stocks**: Tickers espec√≠ficos de acciones europeas
3. **Commodities**: Tickers espec√≠ficos de materias primas
4. **Crypto**: Tickers espec√≠ficos de criptomonedas

**Importante**: Los tickers usados en fine-tuning son ESPEC√çFICOS de cada mercado y diferentes de los que se usar√°n en benchmarks.

**M√©todo**: Walk-Forward Analysis

```
Train Window: 24 meses
Val Window: 6 meses
Step Forward: 3 meses

|----Train----|Val|
    |----Train----|Val|
        |----Train----|Val|
```

**Prevenci√≥n Look-Forward Bias**:
- ‚úÖ Nunca usar datos futuros
- ‚úÖ Validar en out-of-sample
- ‚úÖ Ventanas temporales no solapadas
- ‚úÖ Simula trading real

**Output**: 4 modelos especializados √ó N folds

---

### FASE 3: Generaci√≥n de Se√±ales y Validaci√≥n ‚ùå PENDIENTE

**Objetivo**: Generar se√±ales de trading (LONG/SHORT) de alta confianza y validarlas con benchmarks

#### 3.1 Generaci√≥n de Se√±ales

**Tipos de Se√±ales**:
- **LONG**: Se√±ales de compra (predicci√≥n de subida)
- **SHORT**: Se√±ales de venta (predicci√≥n de bajada)

**Condiciones para Se√±al LONG (TODAS deben cumplirse)**:

1. **Prob D√≠a**: `P(subida_pr√≥xima_vela) > 90%`
2. **Prob Horizonte**: `P(subida_horizonte) > 90%`
3. **Rango Bollinger**: `expected_return_up > 2 √ó œÉ_Bollinger`

**Condiciones para Se√±al SHORT (TODAS deben cumplirse)**:

1. **Prob D√≠a**: `P(bajada_pr√≥xima_vela) > 90%`
2. **Prob Horizonte**: `P(bajada_horizonte) > 90%`
3. **Rango Bollinger**: `expected_return_down > 2 √ó œÉ_Bollinger`

**Horizontes Temporales**:

| Tipo | Horizonte | D√≠as | Uso |
|------|-----------|------|-----|
| Corto | 1 semana | 5 | Day/Swing trading |
| Medio-Corto | 2 semanas | 10 | Swing trading |
| Medio | 1 mes | 22 | Position trading |
| Medio-Largo | 2 meses | 44 | Investment |

**C√°lculo Bollinger Bands**:
- Calculadas sobre cada horizonte temporal
- Solo datos hist√≥ricos (evita look-forward bias)
- 2 desviaciones est√°ndar (ancho de banda similar a Bollinger tradicional)

#### 3.2 Validaci√≥n con Benchmarks

**Importante**: Los benchmarks usan √çNDICES de cada mercado, diferentes de los tickers usados en fine-tuning.

**Benchmarks por Mercado**:
1. **US Stocks**: √çndices como SPY, QQQ, DIA (diferentes de tickers de tuning)
2. **EU Stocks**: √çndices como EWU, EWG, EWQ (diferentes de tickers de tuning)
3. **Commodities**: √çndices como GLD, USO, DBA (diferentes de tickers de tuning)
4. **Crypto**: √çndices como BTC, ETH (si no est√°n en tuning)

**Proceso de Validaci√≥n**:
1. Modelo especializado genera se√±ales (LONG/SHORT) en √≠ndices benchmark
2. Se ejecutan entradas y salidas seg√∫n se√±ales
3. Se mide performance real de la estrategia

#### 3.3 M√©tricas

**M√©tricas de Entrenamiento (durante generaci√≥n de se√±ales)**:
- **Tasa de acierto de se√±ales**: % de se√±ales que resultan correctas
- **Precisi√≥n LONG**: % de se√±ales LONG correctas
- **Precisi√≥n SHORT**: % de se√±ales SHORT correctas
- **False Positive Rate**: % de se√±ales incorrectas
- **Signal Frequency**: N√∫mero de se√±ales generadas por periodo

**M√©tricas de Benchmark (en √≠ndices)**:
- **Win Rate**: % de operaciones ganadoras
- **Profit Factor**: Ganancia total / P√©rdida total
- **Sharpe Ratio**: Retorno ajustado por riesgo
- **Max Drawdown**: P√©rdida m√°xima desde pico
- **Average Return per Trade**: Retorno promedio por operaci√≥n
- **Total Return**: Retorno acumulado del periodo

---

### FASE 4: Optimizaci√≥n y Monitoreo ‚ùå FUTURO

**Objetivo**: Ajustar el sistema de benchmarking y detectar deterioro de la estrategia

#### 4.1 Ajuste del Benchmark

**Pendiente para implementaci√≥n posterior**:
- Optimizaci√≥n de par√°metros de entrada/salida
- Refinamiento de umbrales de probabilidad
- Ajuste de gesti√≥n de riesgo (stop-loss, take-profit)
- Testing de diferentes horizontes temporales

#### 4.2 Detecci√≥n de Deterioro

**Sistema de Monitoreo Temporal**:
- M√©tricas de performance por periodo
- Detecci√≥n de cambios de r√©gimen de mercado
- Alertas de degradaci√≥n de modelo
- Comparaci√≥n de performance actual vs hist√≥rica

**Indicadores de Deterioro**:
- **Win Rate Drift**: Ca√≠da sostenida del % de acierto
- **Sharpe Ratio Decline**: Reducci√≥n del retorno ajustado por riesgo
- **Max Drawdown Increase**: Aumento de p√©rdidas m√°ximas
- **Signal Frequency Change**: Cambio significativo en n√∫mero de se√±ales

**Acciones ante Deterioro**:
1. Re-entrenamiento con datos m√°s recientes
2. Re-ajuste de walk-forward windows
3. Revisi√≥n de tickers/√≠ndices de benchmark
4. Evaluaci√≥n de cambio estructural del mercado

---

## üíæ ESTADO ACTUAL DEL PROYECTO

### ‚úÖ COMPLETADO

**C√≥digo**:
- [x] Arquitectura MarketGPT (transformer GPT-style)
- [x] MarketGPTMultiAsset (multi-asset con embeddings)
- [x] OHLCTokenizer (quantile-based, 4 canales)
- [x] Data loaders para 3 cases
- [x] Scripts entrenamiento multi-GPU (2√óA100)
- [x] Train/Val/Test splits temporales
- [x] Evaluaci√≥n final en test set ‚úÖ **A√ëADIDO HOY**
- [x] Distributed training (DataParallel)

**Documentaci√≥n**:
- [x] SYSTEM_ARCHITECTURE.md (arquitectura completa)
- [x] QUICK_REFERENCE.md (referencia r√°pida)
- [x] TRAINING_GUIDE.md (gu√≠a multi-GPU)
- [x] READMEs por case (A, B, C)
- [x] CLAUDE_CONTEXT.md (este archivo)

**Bugs Corregidos**:
- [x] Case C: DatetimeArray.sort() error ‚Üí `sorted()`
- [x] Case C: CUDA module error ‚Üí removido
- [x] Cases A/B/C: Test set no se usaba ‚Üí a√±adida evaluaci√≥n final
- [x] Case B: Faltaba --num-gpus ‚Üí a√±adido

### ‚ùå PENDIENTE

**Fase 2: Fine-Tuning por Mercado**:
- [ ] Scripts de fine-tuning por mercado (US, EU, Commodities, Crypto)
- [ ] Pipeline walk-forward analysis completo
- [ ] Gesti√≥n de m√∫ltiples folds
- [ ] Ensemble de modelos por fold
- [ ] Definir tickers espec√≠ficos por mercado para tuning

**Fase 3: Generaci√≥n de Se√±ales y Validaci√≥n**:
- [ ] Motor de generaci√≥n de se√±ales (LONG/SHORT)
- [ ] C√°lculo multi-horizonte Bollinger Bands (1w, 2w, 1m, 2m)
- [ ] Sistema de predicci√≥n de probabilidades por horizonte
- [ ] Definir √≠ndices de benchmark por mercado (diferentes de tuning)
- [ ] Sistema de backtesting en benchmarks
- [ ] M√©tricas de entrenamiento (tasa acierto, precision LONG/SHORT)
- [ ] M√©tricas de benchmark (win rate, profit factor, sharpe, drawdown)
- [ ] Logging de se√±ales generadas

**Fase 4: Optimizaci√≥n y Monitoreo (Futuro)**:
- [ ] Sistema de ajuste de par√°metros de benchmark
- [ ] Detecci√≥n de deterioro temporal
- [ ] Dashboard de m√©tricas de deterioro
- [ ] Sistema de re-entrenamiento autom√°tico

**Infraestructura General**:
- [ ] Dashboard de monitoreo en tiempo real
- [ ] API de se√±ales
- [ ] Base de datos de se√±ales hist√≥ricas
- [ ] Sistema de alertas

---

## üìÅ ESTRUCTURA DEL PROYECTO

```
stock_predictor/
‚îú‚îÄ‚îÄ üìÑ CLAUDE_CONTEXT.md           ‚Üê Este archivo
‚îú‚îÄ‚îÄ üìÑ SYSTEM_ARCHITECTURE.md      ‚Üê Arquitectura completa
‚îú‚îÄ‚îÄ üìÑ QUICK_REFERENCE.md          ‚Üê Referencia r√°pida
‚îú‚îÄ‚îÄ üìÑ TRAINING_GUIDE.md           ‚Üê Gu√≠a entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ üìÇ common/                     ‚Üê M√≥dulos compartidos
‚îÇ   ‚îú‚îÄ‚îÄ market_gpt.py              ‚Üê Transformer base
‚îÇ   ‚îú‚îÄ‚îÄ market_gpt_multi.py        ‚Üê Multi-asset model
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py               ‚Üê OHLC tokenizer
‚îÇ   ‚îú‚îÄ‚îÄ training_monitor.py        ‚Üê Monitor entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ distributed_utils.py       ‚Üê Multi-GPU utils
‚îÇ
‚îú‚îÄ‚îÄ üìÇ case_a_full_market/         ‚Üê 600 assets
‚îÇ   ‚îú‚îÄ‚îÄ universal_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ train_full.py              ‚Üê Training script (2 GPUs)
‚îÇ   ‚îú‚îÄ‚îÄ configs/full_market_config.json
‚îÇ   ‚îú‚îÄ‚îÄ slurm_scripts/train_full_a100.sh
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìÇ case_b_reduced/             ‚Üê 100 assets
‚îÇ   ‚îú‚îÄ‚îÄ multi_market_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ train_reduced.py           ‚Üê Training script (2 GPUs)
‚îÇ   ‚îú‚îÄ‚îÄ configs/reduced_config.json
‚îÇ   ‚îú‚îÄ‚îÄ slurm_scripts/train_reduced_a100.sh
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ üìÇ case_c_crypto/              ‚Üê 20 cryptos
‚îÇ   ‚îú‚îÄ‚îÄ crypto_data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ train_crypto.py            ‚Üê Training script (2 GPUs)
‚îÇ   ‚îú‚îÄ‚îÄ configs/crypto_prototype.json
‚îÇ   ‚îú‚îÄ‚îÄ slurm_scripts/train_crypto_a100.sh
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ üìÇ checkpoints/                ‚Üê Modelos entrenados
    ‚îú‚îÄ‚îÄ case_a_full_market/
    ‚îú‚îÄ‚îÄ case_b_reduced/
    ‚îî‚îÄ‚îÄ case_c_crypto/
```

---

## üîë CONCEPTOS CLAVE

### 1. Tokenizaci√≥n OHLC
```python
# Convierte precios OHLC a tokens discretos
# M√©todo: Quantile-based binning
# Canales: 4 (Open, High, Low, Close)
# Vocab size: 1024-4096 bins

OHLCTokenizer.encode(ohlc) ‚Üí token_ids
```

### 2. Multi-Asset Embeddings
```python
# El modelo aprende embeddings por:
# - Asset ID (identificador √∫nico del activo)
# - Category ID (US stocks, EU stocks, crypto, etc.)

model(tokens, asset_id, category_id) ‚Üí logits
```

### 3. Walk-Forward Analysis
```
Evita look-forward bias:
- Entrena en ventana pasada (2 a√±os)
- Valida en ventana siguiente (6 meses)
- Avanza 3 meses
- Repite

Simula trading real en el tiempo
```

### 4. Prevenci√≥n de Look-Forward Bias
```
‚úì Divisi√≥n temporal (no aleatoria)
‚úì Test set solo UNA vez
‚úì Bollinger solo datos hist√≥ricos
‚úì Tokenizer fit solo en train
‚úì Sin informaci√≥n futura en features
‚úì Timestamps estrictos
```

### 5. Se√±ales de Alta Confianza
```
Solo genera se√±al si:
  P(subida_d√≠a) > 90%
  AND
  P(subida_horizonte) > 90%
  AND
  expected_return > 2œÉ_Bollinger

‚Üí Triple filtro de confianza
```

---

## üöÄ COMANDOS FRECUENTES

### Entrenar Models

```bash
# Case C (m√°s r√°pido, 1-2 d√≠as)
cd case_c_crypto/slurm_scripts
sbatch train_crypto_a100.sh

# Case B (medio, 3-5 d√≠as)
cd case_b_reduced/slurm_scripts
sbatch train_reduced_a100.sh

# Case A (completo, 7-10 d√≠as)
cd case_a_full_market/slurm_scripts
sbatch train_full_a100.sh
```

### Monitorear

```bash
# Ver jobs
squeue -u $(whoami)

# Logs en tiempo real
tail -f case_c_crypto/logs/crypto_*.out

# Ver GPUs
ssh <node>
nvidia-smi
```

### Checkpoints

```
checkpoints/case_X/<experiment>/
‚îú‚îÄ‚îÄ best_model.pt          ‚Üê Mejor modelo (val_loss)
‚îú‚îÄ‚îÄ test_results.json      ‚Üê M√©tricas en test
‚îú‚îÄ‚îÄ training_log.json      ‚Üê Historial entrenamiento
‚îú‚îÄ‚îÄ tokenizer.pkl          ‚Üê Tokenizer fitted
‚îî‚îÄ‚îÄ asset_info.json        ‚Üê Mapeo assets
```

---

## üìä DETALLES T√âCNICOS

### Hardware por Case
- **GPUs**: 2√óA100-40GB (un nodo, DataParallel)
- **CPUs**: 64 (32 por GPU)
- **RAM**: 128GB (64GB por GPU)
- **Batch size**: 32 base ‚Üí 64 efectivo (32√ó2 GPUs)

### Model Architecture (Case A - Full)
```python
vocab_size = 4096
context_length = 512
d_model = 768
num_layers = 12
num_heads = 12
d_ff = 3072
dropout = 0.1
asset_embed_dim = 64
category_embed_dim = 32

Total params: ~85M
```

### Model Architecture (Case B - Reduced)
```python
vocab_size = 2048
context_length = 256
d_model = 512
num_layers = 8
num_heads = 8
d_ff = 2048

Total params: ~45M
```

### Model Architecture (Case C - Crypto)
```python
vocab_size = 1024
context_length = 128
d_model = 256
num_layers = 6
num_heads = 8
d_ff = 1024

Total params: ~25M
```

---

## üéØ WORKFLOW DE TRABAJO T√çPICO

### Nueva Sesi√≥n

1. **Cargar contexto**: `/context` (este comando)
2. **Revisar estado**: Ver secci√≥n "Estado Actual"
3. **Identificar tarea**: Consultar secci√≥n "Pendiente"
4. **Consultar docs**: Ver SYSTEM_ARCHITECTURE.md si es necesario

### Implementar Nueva Feature

1. **Consultar arquitectura**: SYSTEM_ARCHITECTURE.md
2. **Ver ejemplos**: Revisar code existente en common/
3. **Implementar**: Seguir patrones del proyecto
4. **Testear**: Usar datos de validaci√≥n
5. **Documentar**: Actualizar READMEs y este archivo

### Debugging

1. **Revisar logs**: `case_*/logs/*.err`
2. **Verificar GPU**: `nvidia-smi` en nodo
3. **Consultar fixes**: Secci√≥n "Bugs Corregidos"
4. **Checkear paths**: Todo en `/mnt/netapp2/...`

---

## üìñ REFERENCIAS R√ÅPIDAS

### Documentos Principales
- **Arquitectura completa**: `SYSTEM_ARCHITECTURE.md`
- **Referencia r√°pida**: `QUICK_REFERENCE.md`
- **Gu√≠a entrenamiento**: `TRAINING_GUIDE.md`

### Secciones Importantes de SYSTEM_ARCHITECTURE.md
- Secci√≥n 2: Fase 1 (Pre-entrenamiento)
- Secci√≥n 3: Fase 2 (Fine-tuning + Walk-forward)
- Secci√≥n 4: Fase 3 (Generaci√≥n de se√±ales)
- Secci√≥n 5: Prevenci√≥n look-forward bias
- Secci√≥n 6: Pipeline producci√≥n

### Preguntas Frecuentes

**P: ¬øC√≥mo funcionan las se√±ales?**
‚Üí Ver SYSTEM_ARCHITECTURE.md secci√≥n 4

**P: ¬øQu√© es walk-forward?**
‚Üí Ver SYSTEM_ARCHITECTURE.md secci√≥n 3.3

**P: ¬øC√≥mo entrenar un case?**
‚Üí Ver TRAINING_GUIDE.md

**P: ¬øC√≥mo evitar look-forward bias?**
‚Üí Ver SYSTEM_ARCHITECTURE.md secci√≥n 5

**P: ¬øEstado del proyecto?**
‚Üí Ver este archivo, secci√≥n "Estado Actual"

---

## üîÑ √öLTIMAS ACTUALIZACIONES

### 2025-01-06 (Hoy - Actualizaci√≥n 2)

**Aclaraciones Arquitectura**:
- ‚úÖ Clarificado: Modelos son "r√©plicas de LLM" entrenadas con datos de bolsa
- ‚úÖ A√±adido: Se√±ales LONG y SHORT (no solo compra)
- ‚úÖ Especificado: Benchmarks usan √çNDICES diferentes de tickers de tuning
- ‚úÖ Definido: M√©tricas de entrenamiento Y de benchmark
- ‚úÖ A√±adido: FASE 4 (optimizaci√≥n benchmark + detecci√≥n deterioro)

**Documentaci√≥n Actualizada**:
- CLAUDE_CONTEXT.md con aclaraciones completas
- FASE 3 expandida con se√±ales LONG/SHORT
- Secci√≥n de benchmarks con √≠ndices espec√≠ficos
- M√©tricas detalladas (entrenamiento + benchmark)
- Plan futuro de detecci√≥n de deterioro

**Conceptos Clave Aclarados**:
- 3 modelos base (Cases A, B, C) = r√©plicas LLM con datos financieros
- Fine-tuning usa tickers espec√≠ficos por mercado
- Benchmarks usan √≠ndices DIFERENTES (SPY, QQQ, GLD, etc.)
- Se√±ales LONG (subida) y SHORT (bajada) con 90% confianza
- Walk-forward evita look-forward bias

### 2025-01-06 (Hoy - Actualizaci√≥n 1)

**A√±adido**:
- ‚úÖ Evaluaci√≥n en test set para Cases A, B, C
- ‚úÖ Fix bug Case C (DatetimeArray.sort)
- ‚úÖ Fix bug Case C (CUDA module)
- ‚úÖ A√±adido --num-gpus a Case B
- ‚úÖ Documentaci√≥n completa (3 documentos principales)
- ‚úÖ Sistema de contexto con /context y /ctx

**Corregido**:
- Test set se creaba pero NO se usaba ‚Üí Ahora se eval√∫a al final
- Cases A/B/C ahora reportan test_loss y test_accuracy
- Multi-GPU configurado correctamente (2 GPUs por case)

**Documentado**:
- Sistema de fases completo
- Walk-forward analysis en detalle
- Sistema de se√±ales
- Prevenci√≥n de look-forward bias

---

## üí° NOTAS IMPORTANTES

### Al Iniciar Sesi√≥n
1. **Siempre** ejecutar `/context` al inicio
2. Revisar "Estado Actual" para saber qu√© est√° hecho
3. Consultar "Pendiente" para pr√≥ximas tareas
4. Usar SYSTEM_ARCHITECTURE.md como referencia t√©cnica

### Al Implementar
- Seguir patrones existentes en `common/`
- Mantener consistencia con nomenclatura
- Documentar cambios en este archivo
- Actualizar "Estado Actual" si se completa algo

### Al Hacer Cambios
- Actualizar secci√≥n "√öltimas Actualizaciones"
- Si afecta arquitectura ‚Üí actualizar SYSTEM_ARCHITECTURE.md
- Si es nuevo comando ‚Üí actualizar QUICK_REFERENCE.md
- Si es bug ‚Üí a√±adir a "Bugs Corregidos"

---

## üéì FILOSOF√çA DEL PROYECTO

1. **No Look-Forward Bias**: Nunca usar informaci√≥n futura
2. **Alta Confianza**: Solo se√±ales con >90% probabilidad
3. **Validaci√≥n Rigurosa**: Walk-forward en m√∫ltiples periodos
4. **Especializaci√≥n**: Modelos espec√≠ficos por mercado
5. **Documentaci√≥n**: Todo debe estar documentado
6. **Reproducibilidad**: Scripts SLURM versionados

---

**FIN DEL CONTEXTO**

> Al leer este archivo tienes contexto completo del proyecto MarketGPT.
> Para detalles t√©cnicos, consulta SYSTEM_ARCHITECTURE.md
> Para comandos r√°pidos, consulta QUICK_REFERENCE.md
